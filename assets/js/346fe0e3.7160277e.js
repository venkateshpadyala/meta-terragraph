"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[754],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>u});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),c=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),d=c(n),u=i,h=d["".concat(l,".").concat(u)]||d[u]||m[u]||r;return n?a.createElement(h,o(o({ref:t},p),{},{components:n})):a.createElement(h,o({ref:t},p))}));function u(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,o=new Array(r);o[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,o[1]=s;for(var c=2;c<r;c++)o[c]=n[c];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},9796:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var a=n(7462),i=(n(7294),n(3905));const r={},o="PTP & SyncE",s={unversionedId:"developer/PTP_SyncE",id:"developer/PTP_SyncE",title:"PTP & SyncE",description:"This document describes Terragraph's software implementations for the IEEE",source:"@site/../docs/developer/PTP_SyncE.md",sourceDirName:"developer",slug:"/developer/PTP_SyncE",permalink:"/docs/developer/PTP_SyncE",draft:!1,editUrl:"https://github.com/terragraph/meta-terragraph/edit/main/docs/../docs/developer/PTP_SyncE.md",tags:[],version:"current",frontMatter:{},sidebar:"developerManualSidebar",previous:{title:"Timing and Synchronization",permalink:"/docs/developer/Timing_Synchronization"},next:{title:"Wi-Fi",permalink:"/docs/developer/WiFi"}},l={},c=[{value:"Overview",id:"overview",level:2},{value:"IEEE 1588/PTP Distributed Transparent Clock",id:"ieee-1588ptp-distributed-transparent-clock",level:2},{value:"Terminology",id:"terminology",level:3},{value:"Basics",id:"basics",level:3},{value:"System Architecture",id:"system-architecture",level:3},{value:"Frequency Syntonization",id:"frequency-syntonization",level:4},{value:"Encapsulation and Tunneling",id:"encapsulation-and-tunneling",level:4},{value:"DN vs. CN",id:"dn-vs-cn",level:4},{value:"Software Requirements",id:"software-requirements",level:3},{value:"PTP Packet Identification",id:"ptp-packet-identification",level:4},{value:"Timestamp Insertion",id:"timestamp-insertion",level:4},{value:"Packet Flow",id:"packet-flow",level:4},{value:"Software Implementation",id:"software-implementation",level:3},{value:"NPU Timestamping",id:"npu-timestamping",level:4},{value:"Configuration",id:"configuration",level:5},{value:"Implementation notes",id:"implementation-notes",level:5},{value:"DPAA2 details",id:"dpaa2-details",level:5},{value:"10G PHY Timestamping",id:"10g-phy-timestamping",level:4},{value:"Configuration",id:"configuration-1",level:5},{value:"Implementation notes",id:"implementation-notes-1",level:5},{value:"Hardware Requirements",id:"hardware-requirements",level:3},{value:"Additional Background",id:"additional-background",level:3},{value:"PTP delay request/response measurements",id:"ptp-delay-requestresponse-measurements",level:4},{value:"PTP in cellular networks",id:"ptp-in-cellular-networks",level:4},{value:"PTP for frequency distribution",id:"ptp-for-frequency-distribution",level:5},{value:"PTP for timing distribution",id:"ptp-for-timing-distribution",level:5},{value:"Distributed PTP-TC without GPS at ingress/egress",id:"distributed-ptp-tc-without-gps-at-ingressegress",level:4},{value:"Propagating ingress timestamp to egress",id:"propagating-ingress-timestamp-to-egress",level:4},{value:"Synchronous Ethernet",id:"synchronous-ethernet",level:2},{value:"Terminology",id:"terminology-1",level:3},{value:"Basics",id:"basics-1",level:3},{value:"System Architecture",id:"system-architecture-1",level:3},{value:"SyncE over Terragraph",id:"synce-over-terragraph",level:4},{value:"Network View",id:"network-view",level:4},{value:"Software Requirements",id:"software-requirements-1",level:3},{value:"Software PLL",id:"software-pll",level:4},{value:"ESMC",id:"esmc",level:4},{value:"Software Implementation",id:"software-implementation-1",level:3},{value:"Software PLL",id:"software-pll-1",level:4},{value:"ESMC",id:"esmc-1",level:4},{value:"Configuration",id:"configuration-2",level:5},{value:"Implementation Notes",id:"implementation-notes-2",level:5},{value:"Hardware Requirements",id:"hardware-requirements-1",level:3}],p={toc:c};function m(e){let{components:t,...n}=e;return(0,i.kt)("wrapper",(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"ptp--synce"},"PTP & SyncE"),(0,i.kt)("p",null,"This document describes Terragraph's software implementations for the IEEE\n1588v2 (Precision Time Protocol, or PTP) and Synchronous Ethernet (SyncE)\nprotocols, which are used to meet the synchronization requirements of cellular\nnetworks."),(0,i.kt)("h2",{id:"overview"},"Overview"),(0,i.kt)("p",null,"A common requirement for cellular backhaul is to support IEEE 1588 (PTP) and\nSyncE transport for time (phase) and frequency synchronization. Although PTP can\nbe used for both frequency and phase synchronization, in telecom networks it is\nrarely used for both in the same network. Instead, in telecom networks PTP is\ntypically used only for phase synchronization in conjunction with SyncE for\nfrequency synchronization, or only used for frequency synchronization in systems\nthat do not require phase sync (e.g. FDD networks)."),(0,i.kt)("p",null,"The ITU device characteristics (conformance tests) for telecom clocks in\nG.8273.2 and G.8273.3 explicitly state that the PTP clock's frequency reference\nis provided by the physical layer based on ITU G.8262 EEC-Option 1 (SyncE).\nPerformance requirements for telecom clocks without SyncE for frequency are for\nfurther study."),(0,i.kt)("p",null,"The block diagram below shows Terragraph's reference implementation described in\nthis document."),(0,i.kt)("p",{align:"center"},(0,i.kt)("img",{src:"/figures/puma_mbh_arch.svg",width:"600"})),(0,i.kt)("h2",{id:"ieee-1588ptp-distributed-transparent-clock"},"IEEE 1588/PTP Distributed Transparent Clock"),(0,i.kt)("h3",{id:"terminology"},"Terminology"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"PTP: IEEE 1588v2 Precision Time Protocol"),(0,i.kt)("li",{parentName:"ul"},"OC: 1588/PTP Ordinary Clock"),(0,i.kt)("li",{parentName:"ul"},"BC: 1588/PTP Boundary Clock"),(0,i.kt)("li",{parentName:"ul"},"TC: 1588/PTP Transparent Clock"),(0,i.kt)("li",{parentName:"ul"},"T-GM: Telecom Grand Master"),(0,i.kt)("li",{parentName:"ul"},"T-BC: Telecom Boundary Clock"),(0,i.kt)("li",{parentName:"ul"},"T-TC Telecom Transparent Clock"),(0,i.kt)("li",{parentName:"ul"},"T-TSC: Telecom Time Slave Clock")),(0,i.kt)("h3",{id:"basics"},"Basics"),(0,i.kt)("p",null,"This section describes the requirements and high level design of a ",(0,i.kt)("em",{parentName:"p"},"distributed\nPTP end-to-end transparent clock running over Terragraph")," that uses a common\nclock available to all nodes (GPS) to measure and account for packet residence\ntime. Although the initial implementation makes use of GPS for the Terragraph\ncommon clock, the architecture extends naturally to using any time reference\navailable to all Terragraph nodes. Specifically, 802.1AS can be used in\nconjunction with standard 802.11 services to synchronize an entire Terragraph\nmesh network to the order of 100s of ns ",(0,i.kt)("em",{parentName:"p"},"without requiring GPS at any node"),"."),(0,i.kt)("p",null,"IEEE 1588v2 (PTP) is the preferred method for frequency and timing distribution\nin cellular networks. Supporting PTP transport across the Terragraph network\nenables cellular base stations backhauled by Terragraph to also use Terragraph\nfor frequency and timing distribution rather than requiring a separate\nmechanism. 3GPP TS 36.133 specifies timing (phase) synchronization at base\nstations to within \xb11.5 \xb5s of a common time reference, which is typically\nlocated in the operator's core network. A typical breakdown of the overall\ntiming budget into different network components is shown in the figure below."),(0,i.kt)("p",{align:"center"},(0,i.kt)("img",{src:"/figures/ptp_timing_budget.png",width:"700"})),(0,i.kt)("p",null,"To meet the end-to-end requirement, a loose upper bound on timing error\nintroduced by Terragraph is \xb11 \xb5s between the ingress node connected to the POP\nand egress node connected to the base station. Since TG will be benchmarked\nagainst wired backhaul networks, the synchronization accuracy achievable with TG\nshould be as good as possible, and with the approach outlined below Terragraph\ncan transport PTP flows while introducing less than 250 ns of timing\nuncertainty. Achieving less than 250 ns accuracy leaves at least 750 ns for\nother network components between the T-GM in the core network and the Terragraph\ningress node."),(0,i.kt)("h3",{id:"system-architecture"},"System Architecture"),(0,i.kt)("p",null,"Because Terragraph's TDD (time division duplex) MAC frame structure necessitates\na common time reference across TG nodes, the same common time reference can be\nused to measure the time taken for PTP Sync messages to transit the Terragraph\nnetwork. PTP provides a mechanism for tracking residence time through a network\nelement and removing it from the packet delay calculation. By using this\nmechanism PTP packet latency through the TG network can be decoupled from\ndirectly impacting protocol performance for timing synchronization."),(0,i.kt)("p",null,"From a protocol point of view, using a common time-reference to measure transit\ntime through a multi-hop network and updating the correction field in the Sync\nor Follow Up message can be viewed as a distributed 1588 transparent clock."),(0,i.kt)("p",{align:"center"},(0,i.kt)("img",{src:"/figures/ptp_tc.png",width:"1000"})),(0,i.kt)("p",null,"Although residence time (transit time through TG) can be removed from the packet\ndelay calculation for timing synchronization as outlined in the section below,\nG.8273.3 mentions a residence time limit of 10 ms as generally suitable, which\nshould be viewed as an upper bound on maximum latency allowed for PTP packets\nthrough TG. For frequency synchronization the requirements in G.8261.1 impose\nlimits on Packet Delay Variation (PDV) for a certain percentage of packets to\nwithin ~150 \xb5s."),(0,i.kt)("p",null,"The ingress timestamp can be propagated from ingress to egress in-band using a\nreserved field (see details\n",(0,i.kt)("a",{parentName:"p",href:"#ptp-synce-propagating-ingress-timestamp-to-egress"},"below"),")."),(0,i.kt)("h4",{id:"frequency-syntonization"},"Frequency Syntonization"),(0,i.kt)("p",null,"A PTP transparent clock does not need to maintain a local PTP clock that is\nsynchronized to another PTP clock. Therefore for Terragraph there is no need to\nexplicitly syntonize (frequency sync) the common clock used to measure residence\ntime to a PTP grandmaster clock. In scenarios where tracking clock offset\nbetween the TG common clock and the PTP grandmaster may improve accuracy of the\nresidence time calculation (e.g. PTP transport over a GPS-less Terragraph\nnetwork), the clock offset could be computed in software and used to adjust the\nresidence time calculation accordingly."),(0,i.kt)("h4",{id:"encapsulation-and-tunneling"},"Encapsulation and Tunneling"),(0,i.kt)("p",null,"PTP packets sent through the TG network may have various layers of encapsulation\nor tunneling, and in all cases PTP hardware timestamping must be supported. The\ntimestamping is typically done based on the Start-of-Frame (SOF) delimiter."),(0,i.kt)("p",null,"According to the standard, PTP packets are encapsulated in any of:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Ethernet, IPv4, and IPv6")),(0,i.kt)("p",null,"The PTP packets can also be encapsulated in any of:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"L2TP or LT2P over GRE (no encryption enabled/needed)"),(0,i.kt)("li",{parentName:"ul"},"MPLS"),(0,i.kt)("li",{parentName:"ul"},"IPv6 (including segment routing)")),(0,i.kt)("p",null,"The specific encapsulation used for each MNO should be identified and vetted to\nensure HW classification of PTP packets is supported."),(0,i.kt)("h4",{id:"dn-vs-cn"},"DN vs. CN"),(0,i.kt)("p",null,"The NPU used for CN hardware may not support PTP. In scenarios where a CN would\nnormally be deployed but PTP egress is required, DN hardware will be used\ninstead. This may require minor software changes to treat the PTP-enabled DN as\na CN (e.g. for scheduling purposes)."),(0,i.kt)("h3",{id:"software-requirements"},"Software Requirements"),(0,i.kt)("p",null,"This section describes how PTP packets flow through the Terrragraph network and\nwhat functionality is required to implement a distributed end-to-end transparent\nclock over Terragraph. The goal of an end-to-end transparent clock is to measure\npacket residence time for PTP event messages and update the correction field\naccordingly. An E2E-TC can either be a ",(0,i.kt)("em",{parentName:"p"},"one-step clock")," or a ",(0,i.kt)("em",{parentName:"p"},"two-step clock"),":"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"A ",(0,i.kt)("em",{parentName:"li"},"one-step E2E-TC")," updates the correction field in event messages (",(0,i.kt)("inlineCode",{parentName:"li"},"Sync")," and\n",(0,i.kt)("inlineCode",{parentName:"li"},"Delay_Req"),") as it egresses on the wire using hardware to perform the update."),(0,i.kt)("li",{parentName:"ul"},"A ",(0,i.kt)("em",{parentName:"li"},"two-step E2E-TC")," updates the correction field in the corresponding general\nmessage using software to do the update:",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Residence time measured by the E2E-TC for ",(0,i.kt)("inlineCode",{parentName:"li"},"Sync")," messages is used to update\nthe correction field in the corresponding ",(0,i.kt)("inlineCode",{parentName:"li"},"Follow_Up")," message"),(0,i.kt)("li",{parentName:"ul"},"Residence time measured by the E2E-TC for ",(0,i.kt)("inlineCode",{parentName:"li"},"Delay_Req")," messages is used to\nupdate the correction field in the corresponding ",(0,i.kt)("inlineCode",{parentName:"li"},"Delay_Req")," message")))),(0,i.kt)("p",null,"A PTP end-to-end transparent clock does not participate in the best master clock\nalgorithm (BMCA), does not need to maintain a Local PTP Clock synchronized to an\nexternal PTP clock, and does not need to do any special handling for most of the\nPTP general messages. The table below summarizes the action required by\nTerragraph for each PTP message type."),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Message Name"),(0,i.kt)("th",{parentName:"tr",align:null},"Message Type"),(0,i.kt)("th",{parentName:"tr",align:null},"Action Required"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"Sync")),(0,i.kt)("td",{parentName:"tr",align:null},"Event"),(0,i.kt)("td",{parentName:"tr",align:null},"Special handling")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"Delay_Req")),(0,i.kt)("td",{parentName:"tr",align:null},"Event"),(0,i.kt)("td",{parentName:"tr",align:null},"Special handling")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"Follow_Up")),(0,i.kt)("td",{parentName:"tr",align:null},"General"),(0,i.kt)("td",{parentName:"tr",align:null},"Special handling only for two-step PTP-TC implementation; otherwise pass through")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"Delay_Resp")),(0,i.kt)("td",{parentName:"tr",align:null},"General"),(0,i.kt)("td",{parentName:"tr",align:null},"Special handling only for two-step PTP-TC implementation; otherwise pass through")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"Pdelay_Req")),(0,i.kt)("td",{parentName:"tr",align:null},"Event"),(0,i.kt)("td",{parentName:"tr",align:null},"Peer-delay mechanism not supported")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"Pdelay_Resp")),(0,i.kt)("td",{parentName:"tr",align:null},"Event"),(0,i.kt)("td",{parentName:"tr",align:null},"Peer-delay mechanism not supported")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"Pdelay_Resp_Follow_Up")),(0,i.kt)("td",{parentName:"tr",align:null},"General"),(0,i.kt)("td",{parentName:"tr",align:null},"Peer-delay mechanism not supported")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"Announce")),(0,i.kt)("td",{parentName:"tr",align:null},"General"),(0,i.kt)("td",{parentName:"tr",align:null},"Pass through")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"Management")),(0,i.kt)("td",{parentName:"tr",align:null},"General"),(0,i.kt)("td",{parentName:"tr",align:null},"Pass through")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"Signaling")),(0,i.kt)("td",{parentName:"tr",align:null},"General"),(0,i.kt)("td",{parentName:"tr",align:null},"Pass through")))),(0,i.kt)("p",null,"On NXP-based platforms PTP packet processing may be performed by a ",(0,i.kt)("em",{parentName:"p"},"Linux PTP-TC\napplication")," running in user space, in ",(0,i.kt)("em",{parentName:"p"},"AIOP hardware"),", using ",(0,i.kt)("em",{parentName:"p"},"DPDK"),', or some\ncombination of the options. For the discussion below, "Linux PTP-TC application"\nis used, but that equates to "whatever entity processes/manipulates PTP\npackets".'),(0,i.kt)("p",null,'For simplicity, the discussion below assumes the PTP clock used for hardware\ntimestamping is synchronized to the Terragraph common clock (e.g. GPS). If a\nnode\'s PTP clock is syntonized to the Terragraph common clock but has a known\nnon-zero offset, the Linux PTP-TC application needs to account for the offset\naccordingly. For example, the PTP clock may count "ns since power on", in which\ncase Linux PTP-TC application needs to map "ns since power on" for PTP\ntimestamps to the Terragraph common clock and vice-versa. The same approach\ncould be extended to a node whose PTP clock is not syntonized to the Terragraph\ncommon clock if the frequency offset is known and the Linux PTP-TC application\ncan adjust timestamps accordingly. Such adjustments are mentioned below as "if\nnecessary" or "for further study".'),(0,i.kt)("h4",{id:"ptp-packet-identification"},"PTP Packet Identification"),(0,i.kt)("p",null,"Software must be able to identify when a PTP message enters and leaves the\nTerragraph network at an ingress/egress node. The most straightforward way is to\nmanually configure nodes as a PTP ingress/egress nodes and consider packets\narriving from or heading to the 1G/10G interface on a PTP ingress/egress node as\nentering or leaving the Terragraph network. This approach allows PTP packets to\ntransit intermediate wired interfaces within the Terragraph network without\nterminating the transparent clock, which would result in additional timing\nuncertainty."),(0,i.kt)("p",null,"Packets must be identified by packet classification as PTP if:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"The 2-byte EtherType matches the value reserved for PTP (0x88F7), or"),(0,i.kt)("li",{parentName:"ul"},"UDP port matches PTP reserved port (319 or 320)")),(0,i.kt)("p",null,"Packet classification must be performed after removal of any\nencapsulation/headers."),(0,i.kt)("h4",{id:"timestamp-insertion"},"Timestamp Insertion"),(0,i.kt)("p",null,"PTP timestamps shall be sent from ingress node to egress node in-band using the\n4 bytes at octet 16 of the common message header (Table 18, 1588-2008). This\nfield is renamed ",(0,i.kt)("inlineCode",{parentName:"p"},"messageTypeSpecific")," in 1588v3 and using it for this purpose\nis explicitly allowed by the latest draft 1588v3 standard (see details\n",(0,i.kt)("a",{parentName:"p",href:"#ptp-synce-propagating-ingress-timestamp-to-egress"},"below"),")."),(0,i.kt)("p",null,"For ingress PTP packets the Linux PTP-TC application is responsible for\nconverting the hardware PTP timestamp (typically 8 bytes) to a 4-byte timestamp\nwith ns resolution and placing it in the ",(0,i.kt)("inlineCode",{parentName:"p"},"messageTypeSpecific")," field."),(0,i.kt)("p",null,"For egress PTP packets the Linux PTP-TC application is responsible for\nconverting the 4-byte timestamp contained in the ",(0,i.kt)("inlineCode",{parentName:"p"},"messageTypeSpecific")," field to\nthe format expected by the hardware PTP clock for one-step correction field\nupdate (typically 8 bytes) in addition to setting all 4 bytes of the\n",(0,i.kt)("inlineCode",{parentName:"p"},"messageTypeSpecific")," field to 0."),(0,i.kt)("h4",{id:"packet-flow"},"Packet Flow"),(0,i.kt)("p",null,"This section describes how PTP Event messages flow through the Terragraph\nnetwork and includes platform-specific details for NXP LS1048/1088 based\nimplementations where necessary. The diagram below shows a single PTP message\nentering the Terragraph network at an ingress node, going across one or more\nwireless hops (not shown), and leaving the Terragraph network at an egress node.\nFor PTP ",(0,i.kt)("inlineCode",{parentName:"p"},"Sync")," messages the ingress node is the POP node and the egress node is\nthe CPE node. For PTP ",(0,i.kt)("inlineCode",{parentName:"p"},"Delay_Req")," messages the ingress node is the CPE node and\nthe egress node is the POP node."),(0,i.kt)("p",null,'The discussion below assumes some PTP packets are processed by a Linux PTP\napplication. Although "fast-path" processing is not strictly required, the\nfunctionality can be implemented on the NXP AIOP instead of as a Linux\napplication.'),(0,i.kt)("p",{align:"center"},(0,i.kt)("img",{src:"/figures/ptp_packet_flow.png",width:"900"})),(0,i.kt)("h3",{id:"software-implementation"},"Software Implementation"),(0,i.kt)("p",null,"Terragraph implements a ",(0,i.kt)("em",{parentName:"p"},"distributed end-to-end one-step transparent clock")," in\ntwo layers, depending on hardware availability:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"NPU")," (NXP LS1048A) with ~20ns accuracy, implemented on the host in the\nLinux PTP-TC application."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"10G PHY")," (Microsemi VSC8254) with ~1ns accuracy, with hardware timestamping\nstatically configured through the ",(0,i.kt)("inlineCode",{parentName:"li"},"malibu_char")," application.")),(0,i.kt)("p",null,"The user must enable timestamping on both the network ingress Ethernet\ninterfaces and the network egress interfaces via the ",(0,i.kt)("inlineCode",{parentName:"p"},"timingParams")," node\nconfiguration structure. Note that ingress/egress in this case refers to the\nTerragraph network as a whole; distribution nodes or network interfaces that are\ninternal to the network need only to pass frames along without any special\nhandling."),(0,i.kt)("p",null,"In order for delay to be accurately captured between ingress and egress nodes,\nthe clocks of the two systems must be synchronized. The Terragraph driver\ninterface application synchronizes clocks on the NPU and/or 10G PHY at each 1pps\nstrobe as follows:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"NPU")," via direct DPAA2 register reads/writes to synchronize the NXP PTP\nhardware clock."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"10G PHY")," via a custom datagram socket protocol in ",(0,i.kt)("inlineCode",{parentName:"li"},"malibu_char")," to\nsynchronize the VSC LTC (local time counter) clock.")),(0,i.kt)("h4",{id:"npu-timestamping"},"NPU Timestamping"),(0,i.kt)("p",null,"This section discusses the Linux PTP-TC application, a VPP plugin. Refer to\n",(0,i.kt)("a",{parentName:"p",href:"/docs/developer/VPP_Implementation"},"VPP Implementation")," for additional context about VPP."),(0,i.kt)("h5",{id:"configuration"},"Configuration"),(0,i.kt)("p",null,"VPP does not process PTP packets by default. The user must enable the ",(0,i.kt)("em",{parentName:"p"},"ptptc"),"\nVPP node via the following node configuration fields:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"timingParams.PTP_VPP_INTERFACE")," - The timestamping interface name"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"timingParams.PTP_VPP_OFFSET_NS")," - The factory calibration constant (in ns) to\ncompensate for internal timestamping bias"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"timingParams.PTP_VPP_NXP_PORT")," - The NXP NPU timestamping port number(s),\ni.e. DPMAC indexes, on which to enable the one-step correction field update in\nhardware (or 0 to use software timestamping)")),(0,i.kt)("h5",{id:"implementation-notes"},"Implementation notes"),(0,i.kt)("p",null,"VPP packets are forwarded along a directed graph beginning at input nodes (e.g.\n",(0,i.kt)("inlineCode",{parentName:"p"},"dpdk-input"),"), traversing through one or more internal nodes (e.g.\n",(0,i.kt)("inlineCode",{parentName:"p"},"ip6-lookup"),"), and finally terminating at an output node (e.g.\n",(0,i.kt)("inlineCode",{parentName:"p"},"interface-output"),"). Internal nodes are generally attached to a ",(0,i.kt)("em",{parentName:"p"},"feature arc"),": a\nlist of functions that are called sequentially when processing packets of a\ncertain type. The Linux PTP-TC application applies associated ingress and egress\npacket manipulations based on the direction of the flow of traffic."),(0,i.kt)("p",null,"The ",(0,i.kt)("em",{parentName:"p"},"ptptc")," node is attached to the ",(0,i.kt)("inlineCode",{parentName:"p"},"ip6-unicast")," feature arc. Thus, it will\ninspect any IPv6 unicast packets that arrive at the ingress node to determine\nwhether they are one of the PTP packet types that is modified. If the packet is\na UDP packet with destination port 319 and has PTP type ",(0,i.kt)("inlineCode",{parentName:"p"},"Sync")," or ",(0,i.kt)("inlineCode",{parentName:"p"},"Delay_Req"),",\nthen the lowest order 32 bits of the current 1588 clock timestamp are stored in\nthe packet's ",(0,i.kt)("inlineCode",{parentName:"p"},"message_type_specific")," field."),(0,i.kt)("p",null,"The ",(0,i.kt)("em",{parentName:"p"},"ptptc")," node is also attached to the ",(0,i.kt)("inlineCode",{parentName:"p"},"interface-output")," feature arc. For PTP\npackets arriving at this node, the current timestamp is read from the 1588 clock\nand combined with the lower 32 bits from the ",(0,i.kt)("inlineCode",{parentName:"p"},"message_type_specific")," field added\nby the ingress node, thus recreating the original timestamp. The difference\nbetween the current timestamp and the original timestamp goes into the PTP\n",(0,i.kt)("inlineCode",{parentName:"p"},"correctionField"),", to be consumed by downstream clocks. If requested, the output\nnode will do the ",(0,i.kt)("inlineCode",{parentName:"p"},"correctionField")," update using DPAA2 hardware facilities by\nsetting the original (recovered) timestamp and, in the DPDK driver, copying that\ntimestamp to the frame annotation area."),(0,i.kt)("h5",{id:"dpaa2-details"},"DPAA2 details"),(0,i.kt)("p",null,"The Linux PTP-TC application makes use of a number of features in the DPAA2\nWire-Rate I/O Processor (WRIOP) to support low-latency timestamping, summarized\nbelow:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"RX timestamping.")," This is implemented in DPAA2's DPDK driver for all\npackets, so nothing specific is required; the driver just needs to set the\n",(0,i.kt)("inlineCode",{parentName:"li"},"PKT_RX_TIMESTAMP")," offload flag and copy the timestamp from frame annotation\nword 2 into the ",(0,i.kt)("inlineCode",{parentName:"li"},"rx_timestamp")," dynfield."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"TX one-step update.")," The WRIOP can directly insert the delta between the\ncurrent (at time of transmit) 1588 timestamp and the timestamp stored in the\nframe annotation area (part of the frame description). To perform the update,\nthe hardware needs the following settings:",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"The PTP bit needs to be set in the frame annotation status (frame\nannotation word1)"),(0,i.kt)("li",{parentName:"ul"},"The original RX timestamp needs to be set in the frame annotation (frame\nannotation word 2)"),(0,i.kt)("li",{parentName:"ul"},"The frame control (FRC) field needs to have the WRIOP and the FASV (frame\nannotation status valid) bit set"),(0,i.kt)("li",{parentName:"ul"},"The DPMAC corresponding to the egress interface must have the\n",(0,i.kt)("inlineCode",{parentName:"li"},"SINGLE_STEP")," register configured with the offset of the ",(0,i.kt)("inlineCode",{parentName:"li"},"correctionField"),"\nand the enable and checksum bits set appropriately."))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Timing offset and drift correction."),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"There are several registers that determine the rate at which the 1588\ntimer counter (",(0,i.kt)("inlineCode",{parentName:"li"},"WRIOP_TMR_CNT_{L/H}"),") increments:",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"TMR_ADDEND")," scales the input clock frequency to derive a nominal PTP\nclock frequency"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"TMR_PERIOD"),", part of the ",(0,i.kt)("inlineCode",{parentName:"li"},"TMR_CTRL")," field, is the amount by which\n",(0,i.kt)("inlineCode",{parentName:"li"},"TMR_CNT")," increments"))),(0,i.kt)("li",{parentName:"ul"},"By default, the input clock is 700 MHz, ",(0,i.kt)("inlineCode",{parentName:"li"},"ADDEND")," is (32-bit fixed-point)\n5/7, and ",(0,i.kt)("inlineCode",{parentName:"li"},"PERIOD")," is 2, meaning the nominal clock runs at 500 MHz and the\ncounter counts by two, giving an effective 1 ns period."),(0,i.kt)("li",{parentName:"ul"},"To correct the 1588 clock, ",(0,i.kt)("inlineCode",{parentName:"li"},"TMR_OFFSET_{L/H}")," is programmed with the fixed\ndifference between the two clocks."),(0,i.kt)("li",{parentName:"ul"},"To correct for drift, it is necessary to speed up or slow down the nominal\nPTP clock by adjusting ",(0,i.kt)("inlineCode",{parentName:"li"},"ADDEND")," a small amount. The target value can be\ncomputed as ",(0,i.kt)("inlineCode",{parentName:"li"},"(1e9/(1e9 + drift_ppb)) * original_addend"),".")))),(0,i.kt)("h4",{id:"10g-phy-timestamping"},"10G PHY Timestamping"),(0,i.kt)("p",null,"This section discusses the ",(0,i.kt)("inlineCode",{parentName:"p"},"malibu_char")," application used to configure the\nMicrosemi VSC8254 10G PHY for hardware timestamping. Refer to\n",(0,i.kt)("a",{parentName:"p",href:"/docs/developer/Timing_Synchronization#timing-synchronization-puma-mbh-hardware"},"Puma MBH Hardware"),"\nfor specific hardware details."),(0,i.kt)("h5",{id:"configuration-1"},"Configuration"),(0,i.kt)("p",null,"The user must configure the ",(0,i.kt)("inlineCode",{parentName:"p"},"malibu_char")," application via the following node\nconfiguration fields:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"timingParams.PTP_VSC_CTRL_SOCKET")," - Enable PTP-TC timestamping and use a\ngiven control socket path for LTC clock synchronization"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"timingParams.PTP_VSC_PORT")," - The port used for PTP-TC timestamping and ESMC\ninput/output")),(0,i.kt)("h5",{id:"implementation-notes-1"},"Implementation notes"),(0,i.kt)("p",null,"The ",(0,i.kt)("inlineCode",{parentName:"p"},"malibu_char"),' application is part of the user-space "MESA" library from\nMicrochip. It is patched to perform PTP-TC and SyncE initialization at boot\ntime, and also to run as a daemon with a custom datagram socket protocol for the\npurpose of synchronizing the LTC (local time counter) clock. The Terragraph\ndriver interface application synchronizes the LTC clock (e.g. time-of-day and\nfrequency adjustments) using this interface.'),(0,i.kt)("p",null,"The datagram socket protocol is documented in\n",(0,i.kt)("inlineCode",{parentName:"p"},"vtss_appl_10g_phy_malibu.c:handle_dgram_sock_msg()")," from\n",(0,i.kt)("inlineCode",{parentName:"p"},"recipes-utils/vsc8254phy/files/0005-Add-datagram-socket-interface.patch"),"."),(0,i.kt)("h3",{id:"hardware-requirements"},"Hardware Requirements"),(0,i.kt)("p",null,"The distributed PTP-TC architecture described in this document imposes the\nfollowing ",(0,i.kt)("em",{parentName:"p"},"mandatory hardware requirements"),":"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Hardware timestamping of PTP packets sent or received over any 1G or 10G\ninterface with at least 40 ns accuracy"),(0,i.kt)("li",{parentName:"ul"},"PTP timestamping done for all packets with EtherType 0x88F7 or UDP destination\nport 319 or 320"),(0,i.kt)("li",{parentName:"ul"},"Checks for EtherType and UDP destination port are done respecting the\nstructure of standard protocols when determining attributes of the frame (e.g.\nafter removing any encapsulation)"),(0,i.kt)("li",{parentName:"ul"},"PTP clock used for timestamping is syntonized to a supported time reference\n(e.g. GPS, HTSF)")),(0,i.kt)("p",null,"The following can ",(0,i.kt)("em",{parentName:"p"},"optionally be supported by hardware"),":"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"The NPU can support one-step correction field update to simplify the software\nrequirements for the Linux PTP-TC application"),(0,i.kt)("li",{parentName:"ul"},"Timestamping can be done by the external 1G and/or 10G PHY for improved\naccuracy, but with additional complexity and cost")),(0,i.kt)("p",null,"For NXP based-processors:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"LS1012 does NOT support PTP timestamping in hardware"),(0,i.kt)("li",{parentName:"ul"},"LS1023/1026/1041 supports PTP timestamping in hardware for 2-step operation"),(0,i.kt)("li",{parentName:"ul"},"LS1048/1088 supports PTP timestamping in hardware for 1-step operation\n(superset of 2-step hardware support)")),(0,i.kt)("h3",{id:"additional-background"},"Additional Background"),(0,i.kt)("h4",{id:"ptp-delay-requestresponse-measurements"},"PTP delay request/response measurements"),(0,i.kt)("p",null,"PTP uses an exchange of four timestamps between master and slave devices to\npropagate frequency and phase/timing information from the master clock to the\nslave clock. The master periodically sends ",(0,i.kt)("inlineCode",{parentName:"p"},"Sync")," messages as unicast or\nbroadcast messages, depending on the PTP profile."),(0,i.kt)("p",null,"A single delay request-response procedure is shown in the figure below. The\nmaster sends a ",(0,i.kt)("inlineCode",{parentName:"p"},"Sync")," message at time ",(0,i.kt)("em",{parentName:"p"},"t1"),", which is received at the slave\ndevice at time ",(0,i.kt)("em",{parentName:"p"},"t2"),". A 1-step master includes the timestamp ",(0,i.kt)("em",{parentName:"p"},"t1")," in the ",(0,i.kt)("inlineCode",{parentName:"p"},"Sync"),"\nmessage itself, whereas a 2-step master sends a ",(0,i.kt)("inlineCode",{parentName:"p"},"Follow_Up")," message containing\nthe timestamp \u2014 the protocol accuracy is the same in either case. After\nreceiving a ",(0,i.kt)("inlineCode",{parentName:"p"},"Sync")," message the slave sends a ",(0,i.kt)("inlineCode",{parentName:"p"},"Delay_Req")," to the master at time\n",(0,i.kt)("em",{parentName:"p"},"t3"),", which the slave records locally. The master receives the ",(0,i.kt)("inlineCode",{parentName:"p"},"Delay_Req")," at\ntime ",(0,i.kt)("em",{parentName:"p"},"t4")," and sends the timestamp to the slave in the ",(0,i.kt)("inlineCode",{parentName:"p"},"Delay_Resp")," message."),(0,i.kt)("p",{align:"center"},(0,i.kt)("img",{src:"/figures/ptp_delay_req_resp.png",width:"512"})),(0,i.kt)("p",null,"Using the four timestamps determined during the delay request-response\nprocedure, the slave computes the mean path delay and slave clock offset\nrelative to the master clock as:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"meanPathDelay = [(t2 \u2013 t1) + (t4 \u2013 t3)]/2 = [(t2 \u2013 t3) + (t4 \u2013 t1)]/2\noffsetFromMaster = (t2 \u2013 t1) \u2013 meanPathDelay\n")),(0,i.kt)("p",null,"If any delay asymmetry in the network is known, PTP includes procedures to\ncorrect for it, but unknown or uncompensated delay asymmetry will directly\nintroduce timing error at the slave."),(0,i.kt)("h4",{id:"ptp-in-cellular-networks"},"PTP in cellular networks"),(0,i.kt)("p",null,"Using PTP for frequency distribution vs. timing synchronization imposes very\ndifferent requirements on the network topology, with the latter being much more\ndifficult to achieve."),(0,i.kt)("h5",{id:"ptp-for-frequency-distribution"},"PTP for frequency distribution"),(0,i.kt)("p",null,"Frequency distribution can be done over a generic network that does not contain\nPTP-capable elements as long as the packet delay variation (PDV) requirements\nare met. PTP architectures for frequency distribution and associated performance\nrequirements are given in ITU-T G.826x series specifications."),(0,i.kt)("p",null,'Packet delay variation (PDV) performance requirements are quantified using the\n"floor packet percentage" (FPP) metric. FPP is defined as the percent of packets\nthat experience delay within delta \xb5s of the minimum (or floor) packet delay in\nevery fixed interval.'),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"G.8260 defines the Floor Packet Percentage (FPP) metric"),(0,i.kt)("li",{parentName:"ul"},"G.8261.1 defines a network limit for PDV in terms of FPP"),(0,i.kt)("li",{parentName:"ul"},"G.8263 defines the input tolerance expected of a 1588v2 frequency slave")),(0,i.kt)("p",null,"For reference, the FPP limits specified in G.8261.1 for a 10 node optical\nnetwork with a mix of 1 and 10 Gbps links requires that in every 200 second\nwindow at least 1% of PTP Event Message packets experience delay within 150 \xb5s\nof the minimum delay through the network. Achieving this would impose strict QoS\nrequirements on Terragraph for delivering PTP packets across the network."),(0,i.kt)("h5",{id:"ptp-for-timing-distribution"},"PTP for timing distribution"),(0,i.kt)("p",null,'In addition to PDV, timing synchronization is impacted by asymmetric delays in\nthe network. Network architectures for PTP-based timing distribution typically\nassume "full on-path support" (OPS), which means every network element between\nmaster and slave clocks is either a PTP boundary clock or PTP transparent clock.\nITU-T G.827x specifications cover topologies and performance requirements for\nPTP-based timing distribution.'),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"G.8271.1: Network limits",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Allocates 1000 ns timing error to entire packet network"))),(0,i.kt)("li",{parentName:"ul"},"G.8273: Framework for time and phase synchronization"),(0,i.kt)("li",{parentName:"ul"},"G.8273.2: Telecom boundary and slave clocks (T-BC/T-TSC)"),(0,i.kt)("li",{parentName:"ul"},"G.8273.3: Telecom transparent clocks (T-TC)",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Control of residence time variation is important to limit the irregular\ninter-arrival period of the PTP messages received by a telecom boundary\nclock (T-BC) or by a telecom time slave clock (T-TSC) as this may impact\ntheir performance or lead to the generation of alarms"),(0,i.kt)("li",{parentName:"ul"},"Considers T-TC syntonized by physical layer frequency synchronization\n(T-TC syntonized by PTP is for further study)"))),(0,i.kt)("li",{parentName:"ul"},"G.8275.1: Topologies and PTP profile")),(0,i.kt)("p",null,"An example packet network timing budget from G.8271.1 Table V.1 breaks down as\nfollows:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"100 ns for PRTC + T-GM"),(0,i.kt)("li",{parentName:"ul"},"1000 ns for packet network broken down as:",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"550 ns cTE (10 class A T-BC/T-TC + 1 T-TSC all @ 50 ns cTE)"),(0,i.kt)("li",{parentName:"ul"},"250 ns uncompensated link asymmetries"),(0,i.kt)("li",{parentName:"ul"},"200 ns random"))),(0,i.kt)("li",{parentName:"ul"},"150 ns eNB noise"),(0,i.kt)("li",{parentName:"ul"},"250 ns eNB rearrangement and short holdover")),(0,i.kt)("h4",{id:"distributed-ptp-tc-without-gps-at-ingressegress"},"Distributed PTP-TC without GPS at ingress/egress"),(0,i.kt)("p",null,"As mentioned earlier, timing information can be propagated from one TG node to\nthe next with adequate resolution to meet cellular backhaul requirements using\n802.1AS and high-resolution time of departure/arrival measurements. 802.1AS\nmakes use of existing 802.11 services to compute round trip latency and time\noffset:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Timing Measurement (TM) 802.11v (2011)"),(0,i.kt)("li",{parentName:"ul"},"Fine Timing Measurement (FTM) 802.11-2016")),(0,i.kt)("p",null,"For 802.11 links, timestamp accuracy determines the per-link and ultimately\nend-to-end accuracy; for 802.11ad, in theory, timestamping using a clock\nfrequency of at least 1760 MHz (~0.5 ns) is possible. Current 802.11ad baseband\nchips are expected to achieve at least ~5 ns accuracy without additional\nenhancements."),(0,i.kt)("p",null,"To use the synchronization achieved with TM/FTM as a common time reference for\nthe distributed transparent clock architecture described in this document,\ntiming must be propagated from baseband to the PTP clock used for timestamping.\nA common 1 PPS signal available to the baseband, NPU, and 1G/10G PHY can be used\nfor this purpose."),(0,i.kt)("a",{id:"ptp-synce-propagating-ingress-timestamp-to-egress"}),(0,i.kt)("h4",{id:"propagating-ingress-timestamp-to-egress"},"Propagating ingress timestamp to egress"),(0,i.kt)("p",null,"Calculating residence time at the egress node requires propagating the ingress\ntimestamp to the egress node. The way in which the ingress timestamp is\npropagated to the egress node is outside the scope of the PTP standard, but\nsimilar functionality is required in many PTP implementations. For example, when\ntimestamping is done by an external PHY it may be difficult to track sideband\ninformation about corresponding PTP packets, and for conformance reasons\nadditional bytes cannot be appended to the payload prior to passing it to the\nMAC. A common approach in such scenarios is to use reserved fields in the PTP\nmessage for internal timestamps and to zero-out the field before the message is\nsent on-the-wire to maintain PTP conformance."),(0,i.kt)("p",null,"The 1588v3 specification includes a change to explicitly allow the use of a\nreserved field in the PTP common header for internal timestamping. The change\nrenames the 4 bytes at octet 16 of the common message header (Table 18,\n1588-2008) to ",(0,i.kt)("inlineCode",{parentName:"p"},"messageTypeSpecific")," and explicitly leaves its use for PTP Event\nmessages up to internal implementations (but must be sent as all 0 over the\nwire). For Terragraph, the 4 bytes can be used to transfer a 32-bit nanosecond\ntimestamp derived from the common clock. Rollover must be handled at the egress\nand the egress node must zero-out the ",(0,i.kt)("inlineCode",{parentName:"p"},"messageTypeSpecific")," field before sending\nthe message on-the-wire."),(0,i.kt)("h2",{id:"synchronous-ethernet"},"Synchronous Ethernet"),(0,i.kt)("h3",{id:"terminology-1"},"Terminology"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"SyncE: Synchronous Ethernet"),(0,i.kt)("li",{parentName:"ul"},"ESMC: Ethernet Synchronization Messaging Channel"),(0,i.kt)("li",{parentName:"ul"},"PLL: Phase-Locked Loop"),(0,i.kt)("li",{parentName:"ul"},"DPLL: Digital Phase-Locked Loop"),(0,i.kt)("li",{parentName:"ul"},"NCO: Numerically-Controlled Oscillator"),(0,i.kt)("li",{parentName:"ul"},"TSF: Timing Synchronization Function"),(0,i.kt)("li",{parentName:"ul"},"HTSF: High Resolution Timing Synchronization Function")),(0,i.kt)("h3",{id:"basics-1"},"Basics"),(0,i.kt)("p",null,"Synchronous Ethernet (SyncE) is an ITU-T standard for transferring a clock\nsignal (frequency reference) over an Ethernet physical layer. SyncE is used\nextensively in telecom networks for high-accuracy frequency synchronization of\ncellular base stations to primary time reference clocks located elsewhere in the\nnetwork. The primary standards are:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"ITU G.8261: SyncE architecture and performance limits (network)"),(0,i.kt)("li",{parentName:"ul"},"ITU G.8262: SyncE clock requirements (equipment)"),(0,i.kt)("li",{parentName:"ul"},"ITU G.8264: Protocol aspects of Ethernet Synchronization Messaging Channel\n(ESMC)"),(0,i.kt)("li",{parentName:"ul"},"ITU-T G.781: Synchronization state machine")),(0,i.kt)("p",null,"The main difference between a device that supports SyncE and one that does not\nis that in a device that supports SyncE, the Ethernet PHY is clocked by a stable\nPLL and is able to extract the frequency of its input signal and pass it to its\nsystem clock. Across maximum time and temperature swings SyncE allows a slave\nclock to maintain synchronization to a reference clock many hops away to less\nthan 100 parts per trillion frequency accuracy when in the locked state."),(0,i.kt)("p",null,"Although SyncE was designed with (wired) Ethernet interfaces in mind,\nnon-Ethernet based physical transport is also possible. If both ends of a\nwireless link are viewed as part of a single node, it becomes equivalent to a\nwired backhaul network element that supports SyncE in from the core and SyncE\nout to the base station \u2014 cellular network operators may expect this capability\nto be present in cellular backhaul products."),(0,i.kt)("p",null,"From a protocol perspective, SyncE uses a simple layer 2 messaging channel\ncalled the Ethernet Synchronization Messaging Channel (ESMC) to communicate\ninformation about synchronization status and accuracy to peer nodes. ",(0,i.kt)("em",{parentName:"p"},"ESMC\ninformation PDU")," are sent as heartbeat messages once per second as Ethernet slow\nprotocol frames to provide a continuous indication of the clock quality level\n(QL), which is carried in the ESMC PDU as an SSM code (synchronization status\nmessage from SDH). If a node doesn't receive an ESMC information PDU for five\nseconds it triggers a synchronization state change, and anytime the\nsynchronization state changes a node immediately sends an ",(0,i.kt)("em",{parentName:"p"},"ESMC event PDU"),"\nindicating the new QL to peer nodes."),(0,i.kt)("h3",{id:"system-architecture-1"},"System Architecture"),(0,i.kt)("h4",{id:"synce-over-terragraph"},"SyncE over Terragraph"),(0,i.kt)("p",null,"The primary technical challenge for SyncE support in Terragraph is frequency\ndistribution over the wireless link. Unlike microwave backhaul products where\nthe hardware architecture looks similar to SyncE over Ethernet media:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Terragraph air interface is TDD (time division duplex) instead of FDD\n(frequency division duplex), so continuous frequency transfer is not possible"),(0,i.kt)("li",{parentName:"ul"},"Frequency estimation and compensation is done in the digital domain, so even\nduring transmissions there is no analog recovered clock output that could\ndrive a PLL (this is an expected consequence of the packet-based PHY protocol\nused in Terragraph)")),(0,i.kt)("p",null,"Despite these differences, a Terragraph node can still recover the clock\nfrequency used by its peer node via ",(0,i.kt)("em",{parentName:"p"},"TSF drift"),", or using packet TX and RX\ntimestamps to measure, track, and compensate for frame timing drift between\nnodes over time. The wireless card would periodically determine the phase or\nfrequency between its own clock and its peer clock and communicate the offset to\na numerically-controlled oscillator (NCO) on the SyncE PLL."),(0,i.kt)("p",null,"The Terragraph frame structure is based on TSF timestamps with 1 \xb5s granularity,\nand these timestamps are already used to synchronize multiple TG nodes over the\nair. By driving the upstream node's baseband clock from the synchronized SyncE\nPLL, TSF on the upstream node will stay synchronized with the SyncE reference\nclock and any TSF drift measured by the downstream node can be attributed to a\nfrequency offset between the local clock and the reference clock. The SyncE PLL\ncan then use periodic measurements of TSF drift to correct the frequency of\nclock outputs for the 1G/10G SyncE PHYs."),(0,i.kt)("p",null,'All 802.11ad/ay modems that support fine timing measurements have the hardware\ncapability to generate TX/RX packet timestamps with nanosecond-level accuracy \u2014\nseveral orders of magnitude better than 1 \xb5s TSF. Throughout this document\nsupport for higher resolution timestamps is referred to as "high resolution TSF"\nor HTSF. With HTSF accuracy of 15 ns, a 100 ppt frequency offset results in a\nmeasurable HTSF drift in only 15e-9/100e-12 = 150 seconds. Assuming the\ndownstream node local clock (TCXO/OCXO) and PLL meet stability requirements for\na SyncE reference clock during holdover (e.g. over time, temperature, voltage,\nand load), HTSF (in conjunction with SyncE TCXO/OCXO and PLL) is sufficient to\nmeet ITU requirements for SyncE transport.'),(0,i.kt)("h4",{id:"network-view"},"Network View"),(0,i.kt)("p",null,"The block diagram below shows the relationship between the clock reference flow\nthrough physical layer components and the corresponding ESMC channel."),(0,i.kt)("p",{align:"center"},(0,i.kt)("img",{src:"/figures/synce_flow.png",width:"1000"})),(0,i.kt)("p",null,'Here, a primary reference clock (PRC) in the packet core provides the SyncE\nreference clock. On the ingress Terragraph DN ("DN1"), the hardware SyncE DPLL\nrecovers the clock from the 10G PHY and uses it as the WiGig baseband clock. The\negress Terragraph DN ("DN2") uses the\n',(0,i.kt)("a",{parentName:"p",href:"/docs/developer/Timing_Synchronization#timing-synchronization-ota-sync"},"OTA Sync")," mechanism\nwith high-resolution timestamps and a software PLL to drive the NCO mode clock\nused for egress to the 10G PHY."),(0,i.kt)("h3",{id:"software-requirements-1"},"Software Requirements"),(0,i.kt)("h4",{id:"software-pll"},"Software PLL"),(0,i.kt)("p",null,"One of the most complicated aspects of supporting SyncE in Terragraph is the\nimplementation of the slave PLL to lock to and track the reference clock using\nHTSF phase error measurements. Every BWGD (25.6 ms) heartbeat/keepalive messages\nbetween DN nodes will contain the full 64 bit HTSF timestamp with nanosecond\nresolution. The difference between the slave node's HTSF and peer node's HTSF\nprovides the phase error signal used to drive the phase-locked loop and keep the\nclocks synchronized. The diagram below shows overall PLL operation on the slave\nnode in the locked state."),(0,i.kt)("p",{align:"center"},(0,i.kt)("img",{src:"/figures/synce_pll.png",width:"700"})),(0,i.kt)("p",null,"This requires the following:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Message sent every 25.6 ms from baseband to host with latest phase error\nmeasurement (needs to be handled in quasi-real time and with high reliability)"),(0,i.kt)("li",{parentName:"ul"},"Host application to process phase error measurements at supplied rate\naccording to G.8262 filtering requirements"),(0,i.kt)("li",{parentName:"ul"},"NCO word updates (output of loop filter) sent from host to system synchronizer\nonce every 25.6 ms update cycle over I2C interface")),(0,i.kt)("h4",{id:"esmc"},"ESMC"),(0,i.kt)("p",null,"ESMC support in Terragraph requires software to perform the following actions:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Handle ESMC heartbeat and event messages on SyncE input ports"),(0,i.kt)("li",{parentName:"ul"},"Update sync state according to ESMC messages received"),(0,i.kt)("li",{parentName:"ul"},"Generate ESMC messages on SyncE output ports according to current sync state",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Event messages must be generated upon QL change"),(0,i.kt)("li",{parentName:"ul"},'Heartbeat messages must be generated at 1-second intervals, only when the\nQL is not "DNU" (do-not-use)'),(0,i.kt)("li",{parentName:"ul"},"The maximum ESMC PDUs transmitted per heartbeat interval shall not exceed\n10 (ITU-T G.8264 section 11.3.2.1)"),(0,i.kt)("li",{parentName:"ul"},"The destination address shall be set to the Slow Protocol multicast\naddress 0x0180c2000002 (IEEE 802.3 Annex 57B)")))),(0,i.kt)("p",null,"Packets must be identified by packet classification as ESMC if:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"The 2-byte EtherType matches the value reserved for Ethernet Slow Protocols\n(0x8809)"),(0,i.kt)("li",{parentName:"ul"},"The 1-byte Slow Protocol subtype matches the value 0x0a"),(0,i.kt)("li",{parentName:"ul"},"The 3-byte ITU-OUI matches the value 0x0019a7"),(0,i.kt)("li",{parentName:"ul"},"The 2-byte ITU subtype matches the value 0x0001")),(0,i.kt)("p",null,'Note that the implementation supports only ESMC protocol version 1, as provided\nin the first 3 bits of the "flag" field.'),(0,i.kt)("p",null,'The "best" clock quality level (QL) is determined by the following hierarchy\n(ITU-T G.781 section 5.4.2.1), from highest to lowest preference:'),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"PRC, PRTC, ePRTC"),(0,i.kt)("li",{parentName:"ul"},"SSU-A"),(0,i.kt)("li",{parentName:"ul"},"SSU-B"),(0,i.kt)("li",{parentName:"ul"},"EEC1, eEEC"),(0,i.kt)("li",{parentName:"ul"},"DNU")),(0,i.kt)("h3",{id:"software-implementation-1"},"Software Implementation"),(0,i.kt)("p",null,"Terragraph implements SyncE using two components:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"zl3079x")," driver implementing the slave PLL on the Microsemi ZL30795 system\nsynchronizer chip"),(0,i.kt)("li",{parentName:"ul"},"Linux ESMC application running inside VPP.")),(0,i.kt)("p",null,"The components communicate over\n",(0,i.kt)("inlineCode",{parentName:"p"},"ioctl")," commands to the ",(0,i.kt)("inlineCode",{parentName:"p"},"/dev/zl3079x")," miscdevice."),(0,i.kt)("h4",{id:"software-pll-1"},"Software PLL"),(0,i.kt)("p",null,"The ",(0,i.kt)("inlineCode",{parentName:"p"},"zl3079x")," driver is built as a kernel module and loaded during Terragraph\ndriver initialization. It processes the following messages:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("em",{parentName:"li"},"Northbound:")," HTSF messages from WiGig firmware (",(0,i.kt)("inlineCode",{parentName:"li"},"TG_NB_HTSF_INFO"),") via\nTerragraph driver hook ",(0,i.kt)("inlineCode",{parentName:"li"},"tgd_register_htsf_info_handler()")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("em",{parentName:"li"},"Southbound:")," PLL register reads/writes via I2C client")),(0,i.kt)("p",null,"The SyncE PLL loop filter is implemented as a PI controller, and is driven by\nphase error measurements contained in HTSF messages every BWGD (25.6ms). When no\nmessages are received for some timeout period (1 second), e.g. because a WiGig\nlink went down, then PLL state is reset. In the case of multiple basebands, the\ndriver locks to only the baseband instructed by the ESMC application and drops\nother incoming messages."),(0,i.kt)("p",null,"The driver registers the miscdevice ",(0,i.kt)("inlineCode",{parentName:"p"},"/dev/zl3079x")," to enable an ",(0,i.kt)("inlineCode",{parentName:"p"},"ioctl"),"\ninterface with the ESMC application. It exposes the following calls:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"ZL_IOCTL_SET_MODE")," - Set the DPLL mode, e.g. between ",(0,i.kt)("inlineCode",{parentName:"li"},"NCO")," (0x4) and\n",(0,i.kt)("inlineCode",{parentName:"li"},"REFLOCK_SYNCE")," (0x62)"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"ZL_IOCTL_SET_DEVICE")," - Switch the WiGig device and reset PLL state, e.g. if\nbest received SSM changes"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"ZL_IOCTL_GET_LOCKED"),' - Return whether the the DPLL is in the "locked" output\nstate (1) or not (0)',(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"For ",(0,i.kt)("inlineCode",{parentName:"li"},"NCO")," mode (i.e. lock to WiGig interface), lock is inferred after ~10\nseconds (390 received HTSF messages) without reaching the timeout period"),(0,i.kt)("li",{parentName:"ul"},"For ",(0,i.kt)("inlineCode",{parentName:"li"},"REFLOCK_SYNCE")," mode (i.e. lock to wired interface), lock is\ndetermined by querying the DPLL (i.e. locked to ",(0,i.kt)("inlineCode",{parentName:"li"},"REF3P")," SyncE input,\nholdover-ready status)")))),(0,i.kt)("h4",{id:"esmc-1"},"ESMC"),(0,i.kt)("p",null,"This section discusses the Linux ESMC application, a VPP plugin. Refer to\n",(0,i.kt)("a",{parentName:"p",href:"/docs/developer/VPP_Implementation"},"VPP Implementation")," for additional context about VPP."),(0,i.kt)("h5",{id:"configuration-2"},"Configuration"),(0,i.kt)("p",null,"VPP does not process ESMC packets by default. The user must enable the\n",(0,i.kt)("em",{parentName:"p"},"esmc-input")," VPP node via the following node configuration fields:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"timingParams.ESMC_ENABLED")," - Enable the ESMC application"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"timingParams.PTP_VSC_PORT")," - Generate and handle ESMC protocol frames on the\ncorresponding interface (port 0 = ",(0,i.kt)("inlineCode",{parentName:"li"},"TenGigabitEthernet1"),", port 1 =\n",(0,i.kt)("inlineCode",{parentName:"li"},"TenGigabitEthernet0"),")")),(0,i.kt)("h5",{id:"implementation-notes-2"},"Implementation Notes"),(0,i.kt)("p",null,"When enabled, the ",(0,i.kt)("em",{parentName:"p"},"esmc-input")," node is registered as the handler for Ethernet\nSlow Protocols (",(0,i.kt)("inlineCode",{parentName:"p"},"ETHERNET_TYPE_SLOW_PROTOCOLS"),") via\n",(0,i.kt)("inlineCode",{parentName:"p"},"ethernet_register_input_type()"),". VPP only accepts a single handler for each\nEtherType, so ",(0,i.kt)("em",{parentName:"p"},"any other Slow Protocol handler is overridden")," (e.g. LACP\nprotocol handler). Any actions that need to be taken in response to received\nESMC packets (e.g. SSM change) are passed to the ",(0,i.kt)("em",{parentName:"p"},"esmc-process")," node, described\nbelow."),(0,i.kt)("p",null,"The ",(0,i.kt)("em",{parentName:"p"},"esmc-process"),' node is a VPP "process" node which runs as a separate thread.\nIt waits for signals from the ',(0,i.kt)("em",{parentName:"p"},"esmc-input")," node or otherwise runs every 1\nsecond, which is the required ESMC heartbeat interval. ESMC state update logic\nis largely contained within this node's ",(0,i.kt)("inlineCode",{parentName:"p"},"esmc_update()")," function, which does the\nfollowing:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Finds the current interface with the best SSM"),(0,i.kt)("li",{parentName:"ul"},"If necessary, issues PLL mode/device changes via ",(0,i.kt)("inlineCode",{parentName:"li"},"ioctl")," commands"),(0,i.kt)("li",{parentName:"ul"},"Broadcasts an ESMC frame across all configured output interfaces")),(0,i.kt)("p",{align:"center"},(0,i.kt)("img",{src:"/figures/synce_esmc.svg",width:"600"})),(0,i.kt)("h3",{id:"hardware-requirements-1"},"Hardware Requirements"),(0,i.kt)("p",null,"In addition to the hardware requirements for PTP, the SyncE architecture\ndescribed in this document requires a system synchronizer clock chip (with SyncE\nDPLL). The Terragraph node local clock (TCXO/OCXO) and PLL must meet stability\nrequirements for a SyncE reference clock during holdover (G.8262 Option 1 and\nOption 2 compliance)."))}m.isMDXComponent=!0}}]);